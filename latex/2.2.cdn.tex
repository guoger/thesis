\chapter{Adapt to Frequent Network Failure and Limited Bandwidth}\label{synch}
%In this chapter, problems are further decomposed and analyzed. A variety of solutions are proposed and investigated. To prevent reinventing the wheel, enormous efforts have been put into studying existing technologies and tools in order to effectively solve the problem. 

%Most of techniques today focus on reducing response time and improving concurrency, rather than offline operation and network partitioning. Even though major companies optimize their server architecture for miliseconds of faster, web service in rural areas is still a question of existance.

%TODO Read-only and Read-write

%Overall goals are:
%\begin{itemize}
%\item To reduce user-perceived latency and bandwidth usage within the context of rural LAN with a narrow upper link.
%\item To serve up-to-date content.
%\item To achieve partition tolerance by continuing service when network failure occurs.
%\end{itemize}

\section{A closer look at the problem} \label{components}
As introduced in section \ref{out_intro}, Moodle is deployed as underlying course management system for OUT E-learning platform. Moodle is an open sourse project written in PHP and well-documented\cite{aosamoodle}\cite{moodledoc}. Similiar to other web applications, it can be deployed in a typical LAMP or LNMP stack. In this chapter, we mainly focus on possible solutions for two problems stated previously, and leave the choice of actual server to chapter \ref{benchmark}

%Moodle components
Moodle is a typical database-driven web application where all the pages are generated on-the-fly based on user request. The whole application is composed of three main components: 
\begin{itemize}
\item PHP source code, typically in \texttt{/var/www/moodle/}
\item A database to store data or metadata including site configuration, student information, course details, events, etc.
\item A directory to store materials and resources, as well as cache and temparory files. Typically it is named as \texttt{moodledata/}
\end{itemize}

%model of problem
The problem addressed previously can be simplified and modelised as following,
see Figure \ref{problem_model}. Each node in the model denotes a local
server/proxy and has a certain amount of users associated with it.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{../images/model_centralized.jpeg}
\includegraphics[width=0.6\textwidth]{../images/model_distributed.jpeg}
\caption{Web Delivery Model}
\label{problem_model}
\end{figure}

%What to store
As simple as the model might be, components in it could be vastly heterogenous
while mapping to different techniques. Content stored in a node can either be web objects,
SQL replies, codes or even entire databases. Communication in between can also be
based on a variety of protocols.

%Interactive session
As an online learning platform, users do not only passivly accept information,
but also interact with Moodle through forum, personal blogs and quiz. All the
changes made by users must be stored and seen everywhere. Thus, the system
should not be read-only under any circumstance.

%Dynamic content


%production and minimum affection
Moodle has been in service and adding new services should affect existing
structure as less as possible. Also, steps of adapting changes should be
properly designed to avoid crushing the service.

%communication overhead
To maintain consistency and serve up-to-date content, a reasonable amount of
communication overhead is necessary and is normally positive proportional to the
extent of consistency. Although, due to the presumption of poor network
connection and narrow bandwidth, different nodes in the system are preferably
decoupled and autonomous.

%Offline operation
The autonomy is also closely correlated to the ability of performing offline
operation. Many distributed systems have the ability to detect and recover from
network partitioning, although it normally leads to a compromise of consistensy
and content freshness. When a user request a page, Moodle loads all previliges of the user, generate pages accordingly and log the session. This results in uncacheble content and interaction-must logins.
It has been proven that consistency, high availability and partition tolerence
are impossible to be achieved at same time\cite{brewer2000towards}\cite{gilbert2002brewer}, necessary assumptions must
be made according to the condition and needs.

%TODO Assumptions
While the majority of web caching and content distribution techniques aim at
better performance and delivery efficiency, we prioritize the ability of
performing basic functionalities during network failure. We tolerate a
relatively loose consistency while ensuring eventual convergence.

%Affordability
Lastly, to realize affordability, we mainly focus on open source techniques and
free ware. Thankfully, many successful projects and tools have been made open
source and publicly available. In the following sections of this chapter, we
evaluate a variety of techniques against the criteria stated above and propose
our solution based upon the conclusion. Several of potential solution are also
tried out.

%TODO logic flow chart

\section{Survey on Techniques to enhance web performance}

\subsection{Content Delivery Network}
Content Delivery Network overlaps with Web Cache Proxy at the concept of pushing web content to users. A Content Delivery Network is a collaborative set of surrogate servers spanning the network, where web contents are mirrored\cite{pathan2008content}. Users will perceive a smaller latency while fetching content from a nearby CDN surrogate server rather than original web server. The essence of CDN is illustrated in figure X
%TODO figure

Since more and more web services are evolving to provide dynamic content, CDN also takes advantages of cachebility hints when dealing with dynamic contents\cite{dilley2002globally}. 

%TODO open source CDN project

\subsection{Simple Web Caching}
An intuitive and common solution for the problem of limited bandwidth is to cache popular web content locally, as illustrated in Figure \ref{with_cache}.
A server-side web cache proxy typically sits in front of web server, attempting to serve user request with cached objects rather than triggering computational workload on web application. Web caching has been proven to be an effective approach to reduce bandwidth usage, user-perceived latency and loads on original server\cite{davison2001web}.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{../images/without_caching.jpeg}
\includegraphics[width=0.6\textwidth]{../images/with_caching.jpeg}
\caption{Serve users without and with a Gateway Cache}
\label{with_cache}
\end{figure}

Web cache is greatly advantageous in our scenario that it does not require modification on web application, except that some TCP optimizations could be done between web cache proxy and web server frontend. Web cache proxy can continue serving requests if offline mode enabled, which also meets our requirements. The traffic between cache proxy and authentic server is standard HTTP request and response. The overhead and frequency of communication mainly depends on cache hit / cache miss ratio, expiration time and cache directory size.

Although, all write traffic traverses cache proxy and goes to original server, which leads to a read-only system immediately when network disconnects. This is magnified when Moodle is taken into consideration, where user logins require interaction with original PHP code and database.
%TODO screen shot

%One important feature of all web cache proxies is replacement strategy which invalidate caches and maintain freshness. A comprehensive survey of existing replacement strategy is presented in \cite{podlipnig2003survey}. However

\subsection{Web Caching with Edge Server}
To address the issue of dynamic content generation and client-server interaction, an intuitive and brute-force solution is to generate user-specific page at the edge. A comprehensive study of edge servers can be found in \ref{pathan2008content}. Four strategies are presented: (a) edge computing (b) content-aware caching (c) content-blind caching (d) data replication, see Figure X
%TODO replication figure
In each of the strategy, the edge server attempts to reply user request on the behalf of original server with the information that is locally available. Edge computing still heavily relies on central database, hence out of our consideration. While CAC and CBC store partial database at the edge, data replication stores a complete copy of the database. When the size and complexity of database permit, data replication is desired since it outperforms other strategies in both response speed and offline operation. Although, it adds another layer of complexity to perform transaction processing and maintain the consistency through mutliple distributed databases. An exhaustive survey is presented in section \ref{database_sync}.

Application code rarely changes in our case and is always on-way synchronized from original server, thus consistency can be relatively easy to achieve by periodically utilizing tools like rsync\ref{tridgell1999efficient}.

%TODO file system

\section{Multi-Master Database Synchronization} \label{database_sync}
Database replication techniques has been intensively deployed over clusters and workstations for redundency and load balancing (Figure X).  A LAN is always assumed by most of database replication techniques, whereas database replicas across the WAN are desired to realize our goals. We prioritize availability by compromising on consistency, as long as the system can reach eventual consistency\ref{vogels2009eventually}. Offline operations on distributed databases implies simutaneous modification on the same entry, which result in conflict after reconnection. Techniques to detect and reconsile conflicts are studied and evaluated.
%TODO transaction process

\subsection{Database Cluster}
Firstly, several databases with native support for replication are studied.

%TODO MySQL cluster figure
%CouchDB
\textbf{CouchDB} \ref{couchdb} is an open source distributed database system developed in Apache. The most attractive feature of CouchDB is that it natively supports bi-directional synchronization among multiple database replicas and offline operations. When one replica is disconnected from the network, it retains autonomy and continues as a fully functional database from user point of view. Although, it fails to be our candidate since it is NoSQL database, whereas Moodle heavily relies on SQL calls and it will a significant task to modify Moodle to use NoSQL database.

%MySQL cluster
\textbf{MySQL Cluster} \ref{mysqlcluster} is an open source distributed database system based on MySQL. It supports database sharding and duplicating. A typical use case of MySQL Cluster is shown in Figure X. Although, redundent copy of database can only be accessed with the presence of management master, and cannot be updated during network failures. Furthermore, database nodes are closely coupled with the assumption of LAN (low latency and high bandwidth).

\subsection{Middleware-based Repliation System}
Several studies also proposed the approaches to solve database synchronization at middleware-level\ref{cecchetc} \ref{amza2003conflict} \ref{plattner2004ganymed}. C-JDBC \ref{cecchetc} is an Java implementation of RAIDb\ref{cecchet2005raidb}, aiming at a framework to manage heterogenous databases. With built-in functionality of scheduling transaction processes, C-JDBC is perceived by users as a single virtual database. Although, the system is still centrally managed and could not handle partitioned network. Ganymed middleware system\ref{plattner2004ganymed}, inspired by C-JDBC, achieves consistency by serializing update/write requests at master and propogating changes to replicas in a lazy fashion. Users see a consistent data state (snapshot isolation), even though stale might it be. The limitation of these two middleware is also clear, that no write can be served during network failures.


\subsection{Multi-Master Sycnhronization System}
Similiar to MySQL Cluster Multi-Master setup, we found three state-of-the-art open source tools to the similiar end.
\begin{itemize}
\item \textbf{Galera}\cite{galera} is an open source synchronous database replication software developed to scale web application and provision high availability. It achieves consistency by optimistic locks and group communication. Galera is quorum-based and handles network partitioning by sacrificing the minority. Hence, Galera lacks the essencial features that we are seeking for and is out of consideration.
\item \textbf{Tungsten}\cite{tungsten} replicates database asynchronously and allows loose consistency. Transactions are commited locally, and then propogated across all other nodes. Tungsten features offline operation and automatical recovery although it leave the responsibility of conflict avoidance completely to the application. Conflicts may disturbe replication and hard to trace.
\item \textbf{SymmetricDS}\cite{symmetricds} is another open source asynchronous database replication management tool. It has several built-in rules to detect and reconsile conflicts. It can be configured flexibly to meet different needs, for example, have different courses store in different sites. Also, one appealing feature is that SymmetricDS support file synchronization as well. Figure X birefly illustrates how SymmetricDS works.
%TODO symmetricds figure
\end{itemize}
We can draw the conclusion from above comparison that SymmetricDS is closest to our critaria and can be properly extended to meet our requirements. In the following section, we explore SymmetricDS in details and propose an approach to extend it.

\subsection{Operational Transformation}

